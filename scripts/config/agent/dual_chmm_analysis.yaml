name: "dual_chmm_${agent.g_value}_${agent.reward_coefficient}_${agent.action_selection.name}_${agent.info_gain_percentage}%"

defaults:
  - encoder: convolutional_64
  - decoder: convolutional_64
  - transition: linear_relu_3x100
  - critic: dual_linear_relu_4x100
  - action_selection: epsilon_greedy

_target_: zoo.agents.AnalysisDualCHMM.AnalysisDualCHMM

# Miscellaneous
n_actions: ${environment.n_actions}
n_states: 10
vfe_lr: 0.0001
efe_lr: 0.0001
discount_factor: 0.95
n_steps_between_synchro: 10000
queue_capacity: 50000
tensorboard_dir: "${tensorboard.directory}"
checkpoint_dir: "${checkpoint.directory}"
task_dir: "${oc.env:DATA_DIRECTORY}/${task.name}/[[DIRECTORY]]/${environment.name}/${agent.name}/${task.seed}/"
reward_coefficient: 5000
g_value: "efe"
efe_loss_update_encoder: False
image_shape: ${tuple:3,64,64}
inhibition_of_return: True
trainable: True
verbose: False

# Information gain scheduling
info_gain_percentage: 100
n_steps_info_gain_incr: 0
